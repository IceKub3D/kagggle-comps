{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90274,"databundleVersionId":10995111,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:46:21.298728Z","iopub.execute_input":"2025-02-15T07:46:21.299113Z","iopub.status.idle":"2025-02-15T07:46:21.317594Z","shell.execute_reply.started":"2025-02-15T07:46:21.299086Z","shell.execute_reply":"2025-02-15T07:46:21.315997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import libraries\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error, make_scorer\n\nfrom lightgbm import LGBMRegressor\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:46:21.319085Z","iopub.execute_input":"2025-02-15T07:46:21.319658Z","iopub.status.idle":"2025-02-15T07:46:21.334843Z","shell.execute_reply.started":"2025-02-15T07:46:21.319614Z","shell.execute_reply":"2025-02-15T07:46:21.333679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load the datasets\n\ntrain = pd.read_csv(\"/kaggle/input/playground-series-s5e2/train.csv\").drop([\"id\"], axis=1)\ntest = pd.read_csv(\"/kaggle/input/playground-series-s5e2/test.csv\")\ntrain_extra = pd.read_csv(\"/kaggle/input/playground-series-s5e2/training_extra.csv\").drop([\"id\"], axis=1)\n\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:55:41.911032Z","iopub.execute_input":"2025-02-15T07:55:41.911433Z","iopub.status.idle":"2025-02-15T07:55:48.385350Z","shell.execute_reply.started":"2025-02-15T07:55:41.911381Z","shell.execute_reply":"2025-02-15T07:55:48.384198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.shape, test.shape, train_extra.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:55:53.730059Z","iopub.execute_input":"2025-02-15T07:55:53.730706Z","iopub.status.idle":"2025-02-15T07:55:53.737463Z","shell.execute_reply.started":"2025-02-15T07:55:53.730653Z","shell.execute_reply":"2025-02-15T07:55:53.736560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# merge the two training sets\n\ntrain = pd.concat([train, train_extra], ignore_index=True)\ntrain.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:55:57.736543Z","iopub.execute_input":"2025-02-15T07:55:57.736948Z","iopub.status.idle":"2025-02-15T07:55:57.853991Z","shell.execute_reply.started":"2025-02-15T07:55:57.736915Z","shell.execute_reply":"2025-02-15T07:55:57.852805Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"def analyze_df(df):\n    print(\"DataFrame Information:\")\n    print(\"----------------------\")\n    display(df.info(verbose=True, show_counts=True))\n    print(\"\\n\")\n\n    print(\"Number of Null Values:\")\n    print(\"----------------------\")\n    display(df.isnull().sum())\n    print(\"\\n\")\n\n    print(\"Number of Duplicated Rows:\")\n    print(\"--------------------------\")\n    display(df.duplicated().sum())\n    print(\"\\n\")\n\n    print(\"Number of Unique Values:\")\n    print(\"------------------------\")\n    display(df.nunique())\n    print(\"\\n\")\n\nanalyze_df(train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:56:04.208824Z","iopub.execute_input":"2025-02-15T07:56:04.210143Z","iopub.status.idle":"2025-02-15T07:56:12.233138Z","shell.execute_reply.started":"2025-02-15T07:56:04.209939Z","shell.execute_reply":"2025-02-15T07:56:12.231821Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are three numeric columns while the rest are categorical columns\nThe analysis revealed that there are several missing values in the dataset across various columns.\nSpecifically, the columns:\n\nBrand:\nMaterial,\nSize,\nWaterproof,\nStyle,\nColor, and\nWeight Capacity (kg) have missing entries.","metadata":{}},{"cell_type":"code","source":"# let's examine the price column\n\n# first we plot a histogram\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\nsns.histplot(x = train[\"Price\"], kde=True, ax=axes[0], color=\"skyblue\")\naxes[0].set_title(\"Price Distribution\")\naxes[0].set_xlabel(\"Price\")\naxes[0].set_ylabel(\"Frequency\")\n\n# then we use a boxplot to see if there any outliers\nsns.boxplot(x = train[\"Price\"], ax=axes[1], color=\"lightcoral\")\naxes[1].set_title(\"Boxplot of Price\")\naxes[1].set_xlabel(\"Price\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:56:18.396810Z","iopub.execute_input":"2025-02-15T07:56:18.397214Z","iopub.status.idle":"2025-02-15T07:56:35.229099Z","shell.execute_reply.started":"2025-02-15T07:56:18.397182Z","shell.execute_reply":"2025-02-15T07:56:35.227911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check the price summary\nprice_summary = train[\"Price\"].reset_index().describe().round(4).style.format(precision=2).background_gradient(cmap=\"Blues\")\ndisplay(price_summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:46:53.541365Z","iopub.execute_input":"2025-02-15T07:46:53.541831Z","iopub.status.idle":"2025-02-15T07:46:53.841189Z","shell.execute_reply.started":"2025-02-15T07:46:53.541779Z","shell.execute_reply":"2025-02-15T07:46:53.840159Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Target Variable Summary\n\nDistribution:\nThe price distribution shows a slightly right-skewed pattern, indicating that most bags are priced around the mid-range, with fewer expensive outliers. The density peak is between \n40\na\nn\nd\n120.\n\nBoxplot outcome:\nThe boxplot reveals the presence of outliers on the higher price end, particularly above $130. However, these are not extremely far from the general range, suggesting they may represent premium products.\n\nSummary Statistics:\n\n* Count: 3,694,318 entries\n* Mean Price: 81.135\n* Standard Deviation: 38.93\n* Minimum Price: 15\n* 25th Percentile (Q1): 47.48\n* Median (Q2): 80.99\n* 75th Percentile (Q3): 114.84\n* Maximum Price: 150\n  \nThe data suggests that while most bags are affordable to mid-priced, a smaller segment caters to the premium range.","metadata":{}},{"cell_type":"code","source":"# let's split our variables into categorical and numeric for easier EDA using the details from\n# train.info\n\ncat_cols = [\n    \"Brand\",\n    \"Material\",\n    \"Size\",\n    \"Laptop Compartment\",\n    \"Waterproof\",\n    \"Style\",\n    \"Color\",\n]\n\nnum_cols = [\"Compartments\", \"Weight Capacity (kg)\", \"Price\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:57:00.091997Z","iopub.execute_input":"2025-02-15T07:57:00.092412Z","iopub.status.idle":"2025-02-15T07:57:00.097348Z","shell.execute_reply.started":"2025-02-15T07:57:00.092362Z","shell.execute_reply":"2025-02-15T07:57:00.096152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizing Numeric Columns\n\nplt.figure(figsize=(14, len(num_cols) * 3))\nfor i , col in enumerate(num_cols):\n    plt.subplot(len(num_cols)//2+1,2,i+1)\n    sns.histplot(x=col, data=train, bins=30, kde=True, palette=\"pastel\")\n    plt.title(col)\n    plt.tight_layout()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:46:53.849091Z","iopub.execute_input":"2025-02-15T07:46:53.849363Z","iopub.status.idle":"2025-02-15T07:47:43.208842Z","shell.execute_reply.started":"2025-02-15T07:46:53.849342Z","shell.execute_reply":"2025-02-15T07:47:43.207634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check for outliers in the numeric columns\n\nplt.figure(figsize=(10, 6))\nfor i , col in enumerate(num_cols,1):\n    plt.subplot(2,2,i)\n    sns.boxplot(x=col, y = \"Brand\", data=train, palette=\"Dark2\")\n    plt.title(col)\n    plt.tight_layout()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:47:43.210064Z","iopub.execute_input":"2025-02-15T07:47:43.210388Z","iopub.status.idle":"2025-02-15T07:47:49.592864Z","shell.execute_reply.started":"2025-02-15T07:47:43.210359Z","shell.execute_reply":"2025-02-15T07:47:49.591630Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are no outliers in the numeric columns","metadata":{}},{"cell_type":"code","source":"# Visualiziing categorical columns\n\nplt.figure(figsize=(10,8))\nfor i ,col in enumerate(cat_cols ,1):\n    plt.subplot(3,3,i)\n    sns.countplot(y=col, data=train)\n    plt.title(col)\n    \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:47:49.594126Z","iopub.execute_input":"2025-02-15T07:47:49.594492Z","iopub.status.idle":"2025-02-15T07:48:06.186236Z","shell.execute_reply.started":"2025-02-15T07:47:49.594452Z","shell.execute_reply":"2025-02-15T07:48:06.185115Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"# create a weight capacity pipeline\n\nweight_capacity_pipe=Pipeline(steps=[('scaler',StandardScaler())])\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('weight_capacity_pipe', weight_capacity_pipe, ['Weight Capacity (kg)']),\n        ('cat_pipeline', Pipeline(steps=[\n            ('encoder', OneHotEncoder())\n        ]), cat_cols)\n    ],\n    remainder='passthrough'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:57:19.509002Z","iopub.execute_input":"2025-02-15T07:57:19.509352Z","iopub.status.idle":"2025-02-15T07:57:19.514892Z","shell.execute_reply.started":"2025-02-15T07:57:19.509327Z","shell.execute_reply":"2025-02-15T07:57:19.513710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split data into features and targe\n\nX_train,X_test,y_train,y_test= train_test_split(train.drop(columns='Price'),train['Price'],test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:57:24.915657Z","iopub.execute_input":"2025-02-15T07:57:24.916031Z","iopub.status.idle":"2025-02-15T07:57:27.883343Z","shell.execute_reply.started":"2025-02-15T07:57:24.916000Z","shell.execute_reply":"2025-02-15T07:57:27.882201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# finnish creating a pipeline\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', LGBMRegressor())\n])\n\n# Perform cross-validation\nrmse_scorer = make_scorer(mean_squared_error, squared=False)\nscores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=rmse_scorer)\n\nprint(f'Cross-Validation RMSE: {np.mean(scores):.4f}')\n\n# Fit the pipeline on the training set\npipeline.fit(X_train, y_train)\n\n# Test set predictions\ny_pred = pipeline.predict(X_test)\ntest_rmse = mean_squared_error(y_test, y_pred, squared=False)\nprint(f'Test Set RMSE: {test_rmse:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:57:32.415560Z","iopub.execute_input":"2025-02-15T07:57:32.415946Z","iopub.status.idle":"2025-02-15T07:59:29.690287Z","shell.execute_reply.started":"2025-02-15T07:57:32.415920Z","shell.execute_reply":"2025-02-15T07:59:29.689175Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prediction and Submission","metadata":{}},{"cell_type":"code","source":"# Make predictions on the test set\npredictions = pipeline.predict(test)\n\n# Create the submission DataFrame\nsubmission = pd.DataFrame({\n    'id': test['id'],         # Ensure 'id' exists in the test set\n    'Price': predictions      # Use predictions on the test set\n})\n\n# Save the DataFrame to a CSV file\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T07:59:44.230105Z","iopub.execute_input":"2025-02-15T07:59:44.230566Z","iopub.status.idle":"2025-02-15T07:59:45.653298Z","shell.execute_reply.started":"2025-02-15T07:59:44.230533Z","shell.execute_reply":"2025-02-15T07:59:45.652071Z"}},"outputs":[],"execution_count":null}]}